# -*- coding: utf-8 -*-
"""BAAI _NLP.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1AmnU9P2FNh3RS0LhjdEcRDv7nSd7d3Qn
"""

print("SHREE RAM")

!pip install anvil-uplink

import anvil.server

anvil.server.connect("server_GZMJ3FGREXONNV7RQ3PFQ6DI-BX4UIUOEXNLMKCT7")





pip install -qqq sentence-transformers imbalanced-learn pandas scikit-learn numpy

#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
Sentence Embeddings (BGE-Large) with Random Forest Classification

This script uses BGE-Large sentence embeddings with a Random Forest classifier
for sentiment analysis and sarcasm detection.
"""

import os
import pandas as pd
import numpy as np
from sentence_transformers import SentenceTransformer
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report
from imblearn.over_sampling import SMOTE


def download_datasets():
    """Download required datasets if they don't exist."""
    datasets = [
        ("https://gist.githubusercontent.com/Phani-2608/1610e06ac549fc3a17c1027eeb9275c1/raw/f07273b926b4a8ff45394b36bfa2b9e969098a1a/consolidated.csv", "consolidated csv")
    ]

    for url, filename in datasets:
        if not os.path.exists(filename):
            print(f"Downloading {filename}...")
            os.system(f"wget {url}")


def load_data():
    df = pd.read_csv("consolidated.csv")
    return df


def get_bert_features(text, tokenizer, model):
    """Extract embeddings using SentenceTransformer model."""
    embedding = model.encode(text, convert_to_numpy=True)
    return embedding


def process_data(df, tokenizer, model):
    """Process data to extract embeddings."""
    print("Extracting sentence embeddings...")
    embeddings = []

    for i, text in enumerate(df['sentence']):
        if i % 100 == 0:
            print(f"Processing {i}/{len(df)} sentences...")
        embedding = get_bert_features(text, tokenizer, model)
        embeddings.append(embedding)

    return np.vstack(embeddings)


def apply_smote(X, y):
    """Apply SMOTE to handle class imbalance."""
    print("Applying SMOTE to balance classes...")
    smote = SMOTE(sampling_strategy='auto', random_state=42)
    X_resampled, y_resampled = smote.fit_resample(X, y)
    return X_resampled, y_resampled


def train_and_evaluate_model(X_train, X_test, y_train, y_test):
    """Train Random Forest model and evaluate its performance."""
    print("Training Random Forest classifier...")
    clf = RandomForestClassifier(
        n_estimators=100,
        random_state=42,
        n_jobs=-1,
        verbose=1
    )

    clf.fit(X_train, y_train)
    predictions = clf.predict(X_test)

    accuracy = accuracy_score(y_test, predictions)
    report = classification_report(y_test, predictions)

    print(f"Accuracy: {accuracy:.4f}")
    print("Classification Report:\n", report)

    return clf, accuracy, report


def main():
    """Main function to orchestrate the entire process."""
    print("Loading BGE-Large sentence embedding model...")
    model = SentenceTransformer('BAAI/bge-large-en-v1.5')
    tokenizer = None  # Not used with SentenceTransformer

    download_datasets()

    df = load_data()
    print(f"Dataset shape: {df.shape}")
    print(f"Class distribution:\n{df['label'].value_counts()}")

    X = process_data(df, tokenizer, model)
    y = df['label'].values

    X_resampled, y_resampled = apply_smote(X, y)
    print(f"Shape after SMOTE: X={X_resampled.shape}, y={y_resampled.shape}")

    X_train, X_test, y_train, y_test = train_test_split(
        X_resampled, y_resampled, test_size=0.2, random_state=42
    )

    model, accuracy, report = train_and_evaluate_model(X_train, X_test, y_train, y_test)

    print("Process completed successfully!")

    return model


if __name__ == "__main__":
    model = main()

def predict_sarcasm(query):

  query_emb = get_bert_features(query, None, SentenceTransformer('BAAI/bge-large-en-v1.5'))
  res = model.predict(query_emb.reshape(1,-1))[0]
  if res:
    return 'The query is sarcastic'
  else:
    return 'the query is not sarcastic'

@anvil.server.callable
def detect_sar_3(input):
  query = 'eating in a tall building helps grow taller'
  sarcasm_text= input
  result = predict_sarcasm(sarcasm_text)

  return sarcasm_text +" : " + result +" from BAAI "

anvil.server.wait_forever()